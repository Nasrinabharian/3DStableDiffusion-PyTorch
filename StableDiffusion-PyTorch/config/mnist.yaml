dataset_params:
  im_path: '/Users/abharian/LDM_Project/StableDiffusion-PyTorch/data/mnist/train/images'
  im_channels: 1
  im_size: 64
  name: 'mnist'
diffusion_params:
  num_timesteps: 1000
  beta_start: 0.0015
  beta_end: 0.0195

ldm_params:
  down_channels: [32, 64, 64, 64]  # Same as in the autoencoder training
  mid_channels: [64, 64]  # Same as the autoencoder
  down_sample: [False, False, False]  # Keep this the same for compatibility
  attn_down: [False, False, False]  # Disable attention to save memory, consistent with training
  time_emb_dim: 64  # Keep it low and consistent
  norm_channels: 4  # Reduced for memory efficiency and matching autoencoder training
  num_heads: 4  # Keep the same reduced number of heads
  conv_out_channels: 32  # Same as the autoencoder
  num_down_layers: 1  # Reduced and kept minimal as in training
  num_mid_layers: 1  # Consistent with autoencoder
  num_up_layers: 1  # Same as training

autoencoder_params:
  z_channels: 16  # Keep consistent with the 1 channel (grayscale)
  codebook_size: 10  # Same as training
  down_channels: [8, 16, 32]  # Consistent with autoencoder training
  mid_channels: [32, 32]  # Same as in training
  down_sample: [True, True]  # Same as the trained model
  attn_down: [False, False]  # No attention layers, consistent with training
  norm_channels: 4  # Consistent with autoencoder training
  num_heads: 2  # Keep reduced for memory efficiency
  num_down_layers: 1  # Consistent with training
  num_mid_layers: 1  # Same as before
  num_up_layers: 1  # Same as the trained autoencoder

train_params:
  seed: 1111
  task_name: 'mnist'
  ldm_batch_size: 1  # Keep minimal for memory management
  autoencoder_batch_size: 1  # Keep minimal for memory management
  disc_start: 1000
  disc_weight: 0.5
  codebook_weight: 1
  commitment_beta: 0.2
  perceptual_weight: 1
  kl_weight: 0.000005
  ldm_epochs: 50  # Same as before
  autoencoder_epochs: 50 #50  # Consistent with the training epochs
  num_samples: 94 #25
  num_grid_rows: 5  # Keep the grid size for visualizations
  ldm_lr: 0.00001  # Keep the learning rate same
  autoencoder_lr: 0.0001  # Same learning rate as before
  autoencoder_acc_steps: 4  # Keep gradient accumulation steps the same
  autoencoder_img_save_steps: 8  # Save images at the same interval
  save_latents: True
  vae_latent_dir_name: '/Users/abharian/LDM_Project/StableDiffusion-PyTorch/mnist/vae_latents'
  vqvae_latent_dir_name: '/Users/abharian/LDM_Project/StableDiffusion-PyTorch/mnist/vqvae_latents'
  ldm_ckpt_name: '/Users/abharian/LDM_Project/StableDiffusion-PyTorch/mnist/ddpm_ckpt.pth'
  vqvae_autoencoder_ckpt_name: '/Users/abharian/LDM_Project/StableDiffusion-PyTorch/mnist/vqvae_autoencoder_ckpt.pth'
  vae_autoencoder_ckpt_name: '/Users/abharian/LDM_Project/StableDiffusion-PyTorch/mnist/vae_autoencoder_ckpt.pth'
  vqvae_discriminator_ckpt_name: '/Users/abharian/LDM_Project/StableDiffusion-PyTorch/mnist/vqvae_discriminator_ckpt.pth'
  vae_discriminator_ckpt_name: '/Users/abharian/LDM_Project/StableDiffusion-PyTorch/mnist/vae_discriminator_ckpt.pth'